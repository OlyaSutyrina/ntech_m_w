{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ntechlab_CNNcustom_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4bS4-EBhcJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "afae2845-083b-46f4-a8ca-2d72e651afa2"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZxHo6rTdZ98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import sys\n",
        "#sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCYRX01c94U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import json\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import trange\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import cv2, sys, copy, scipy\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/data_ntechlab\")\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/Colab Notebooks/data_ntechlab\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L61_aX9040p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Загрузка и преобразование данных. Разбивка датасета в пропорции train_idx/test_idx (0.7/0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsB92-Ia05CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = transforms.Compose(\n",
        "    [transforms.Resize(226),\n",
        "     transforms.CenterCrop(224),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "whole_set = ImageFolder(data_dir, transform = data_transforms) \n",
        "\n",
        "\n",
        "test_idx = list(np.random.choice(range(len(whole_set)), 30000, replace=False))\n",
        "set_test = test_idx.copy()\n",
        "train_idx = list(set(range(len(whole_set))) - set(set_test))\n",
        "\n",
        "\n",
        "trainset_subset = torch.utils.data.Subset(whole_set, train_idx)\n",
        "testset_subset = torch.utils.data.Subset(whole_set, test_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset_subset, batch_size=250, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset_subset, batch_size=250, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndCdb04bHwgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, epoches, criterion, optimizer, trainloader, testloader, device, exp_name=None, scheduler=None):\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    if exp_name:\n",
        "        writer = SummaryWriter('./logs_weeklearns/{}'.format(exp_name))\n",
        "    else:\n",
        "        writer = SummaryWriter('./logs_weeklearns/{}'.format('single_ep'))\n",
        "        \n",
        "    bestval = {'bestvalacc': 0, 'epoch': None, 'trainacc@Bval': None, 'iter': 0}\n",
        "    for e in (range(1, epoches+1)):\n",
        "        \n",
        "        model.train()\n",
        "        meanloss = {'counter':0, 'correct':0, 'total':0}\n",
        "        for X, y in (trainloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X)\n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            bestval['iter'] +=1\n",
        "            meanloss['total'] += len(y)\n",
        "            meanloss['correct'] += (torch.argmax(pred, dim=1) == y).sum().item()\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), global_step=bestval['iter'])\n",
        "\n",
        "\n",
        "        writer.add_scalar(\"train_epoch_Accuracy\", meanloss['correct']/len(trainloader.dataset), global_step=e)\n",
        "        print('Epoch:{} |train_accuracy:{}'.format(e, meanloss['correct']/meanloss['total']))\n",
        "        model.eval()\n",
        "        meanlossval = {'loss':0, 'counter':0, 'correct':0,'total':0}\n",
        "        for X, y in testloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            meanlossval['loss'] += criterion(pred, y).item()\n",
        "            meanlossval['total'] += len(y)\n",
        "            meanlossval['correct'] += (torch.argmax(pred, dim=1) == y).sum().item()\n",
        "\n",
        "        writer.add_scalar(\"test_epoch_Accuracy\", meanlossval['correct']/len(testloader.dataset), global_step=e)\n",
        "        print('Epoch:{} |test_accuracy:{}'.format(e, meanlossval['correct']/meanlossval['total']))\n",
        "        print('--'*50)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "            \n",
        "        if meanlossval['correct']/meanlossval['total'] > bestval['bestvalacc']:\n",
        "            bestval['bestvalacc'] = meanlossval['correct']/meanlossval['total']\n",
        "            bestval['trainacc@Bval'] = meanloss['correct']/meanloss['total']\n",
        "            bestval['epoch'] = e\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "    print(bestval)\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjSd11F6Eji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Архитектура модели"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6uTEkXMlsgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, channels=3 , num_classes=2):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        \n",
        "        self.conv1 = torch.nn.Conv2d(channels, 32, kernel_size=7, stride=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv4 = torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.drop_layer_conv = nn.Dropout(p=0.25)\n",
        "        self.drop_layer_dense = nn.Dropout(p=0.5)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = torch.nn.Linear(64 * 9 * 9, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Block 1\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = self.pool(x)\n",
        "      x = self.drop_layer_conv(x)\n",
        "\n",
        "      # Block 2\n",
        "      x = F.relu(self.conv3(x))\n",
        "      x = F.relu(self.conv4(x))\n",
        "      x = self.pool(x)\n",
        "      x = self.drop_layer_conv(x)\n",
        "      x = x.view(-1, 64 * 9 * 9)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.drop_layer_dense(x)\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pQt_6QAnaoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_5z5w2-lscs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = CNNClassifier()\n",
        "model.to(device)\n",
        "model.apply(weights_init)\n",
        "epoches = 10\n",
        "scheduler = None\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam( model.parameters(),\n",
        "                              lr=1e-4,\n",
        "                              weight_decay=1e-6)\n",
        "exp_name = datetime.now().isoformat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b82z41d4lsZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "ffe9f8e0-b4f2-4b8e-fb1e-731b9a34781f"
      },
      "source": [
        "best_model=train(model, epoches, criterion, optimizer, trainloader, testloader, device, exp_name, scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1 |train_accuracy:0.7818137668014112\n",
            "Epoch:1 |test_accuracy:0.8650333333333333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:2 |train_accuracy:0.8825008213229728\n",
            "Epoch:2 |test_accuracy:0.9120666666666667\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:3 |train_accuracy:0.9095544858518191\n",
            "Epoch:3 |test_accuracy:0.9172\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:4 |train_accuracy:0.9219243240154837\n",
            "Epoch:4 |test_accuracy:0.9331\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:5 |train_accuracy:0.93173734805525\n",
            "Epoch:5 |test_accuracy:0.9222\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:6 |train_accuracy:0.9356082789355654\n",
            "Epoch:6 |test_accuracy:0.8922333333333333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:7 |train_accuracy:0.9376223057035524\n",
            "Epoch:7 |test_accuracy:0.9453666666666667\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:8 |train_accuracy:0.9449927866417175\n",
            "Epoch:8 |test_accuracy:0.9475333333333333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:9 |train_accuracy:0.9476210201545515\n",
            "Epoch:9 |test_accuracy:0.9508\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch:10 |train_accuracy:0.9503635246896828\n",
            "Epoch:10 |test_accuracy:0.9496333333333333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'bestvalacc': 0.9508, 'epoch': 9, 'trainacc@Bval': 0.9476210201545515, 'iter': 2810}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVtz3Cuf593R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Сохранение модели с лучшими параметрами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn8VGWM1wmRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5560f646-f4d3-4c45-8763-c08f4348a775"
      },
      "source": [
        "model_save_name = 'Best_mobnet_all.pth'\n",
        "path = F\"/content/drive/My Drive/Colab Notebooks/{model_save_name}\" \n",
        "torch.save(best_model.state_dict(), path, _use_new_zipfile_serialization=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3a7b2107f894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Best_mobnet_all.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mF\"/content/drive/My Drive/Colab Notebooks/{model_save_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXYA6G8ErZht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}